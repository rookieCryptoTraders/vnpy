import inspect
from collections import defaultdict
from pathlib import Path

# The library to inspect and generate wrappers for
import polars_talib as plta

# The directory where the new factor files will be saved
OUTPUT_DIR = Path(
    "/Users/chenzhao/Documents/crypto_vnpy/vnpy/vnpy/factor/factors/ta_lib"
)

# A template for the Python code of each new factor class.
# Placeholders like {class_name}, {factor_name}, etc., will be filled in.
FACTOR_CLASS_TEMPLATE = """# Auto-generated by factor_generator using polats ta-lib.py
import polars as pl
import polars_talib as plta

from vnpy.factor.template import FactorTemplate
from vnpy.factor.memory import FactorMemory

DEFAULT_DATETIME_COL = "datetime"


class {class_name}(FactorTemplate):
    \"\"\"
    {docstring}
    \"\"\"

    author = "Auto-Generated by FactorGenerator"
    factor_name = "{factor_name}"

    def __init__(self, setting: dict | None = None, vt_symbols: list[str] | None = None, **kwargs):
        \"\"\"
        Initializes the {class_name}.
        Required parameters: {required_param_list}
        \"\"\"
        super().__init__(setting, **kwargs)
        self.vt_symbols: list[str] = vt_symbols if vt_symbols else []

        # --- Parameter Validation and Assignment ---
{param_validation_and_assignment}

    def calculate(self, input_data: dict[str, pl.DataFrame], memory: FactorMemory) -> pl.DataFrame:
        \"\"\"Calculates the indicator by iterating through symbols and executing eagerly.\"\"\"
        # --- Input Data Validation ---
{input_data_validation}

        # --- Eager Calculation Loop ---
        df_base = input_data.get("close") or next(iter(input_data.values()))
        symbol_columns = [col for col in df_base.columns if col != DEFAULT_DATETIME_COL]
        if self.vt_symbols:
            symbol_columns = [col for col in symbol_columns if col in self.vt_symbols]

        if not symbol_columns:
            return pl.DataFrame(data={{}}, schema=self.get_output_schema())

        kwargs = {{ {kwargs_for_call} }}
        output_series_list = []

        for symbol in symbol_columns:
            # Build the keyword arguments by extracting the pl.Series for this symbol
            # E.g., {{'high': input_data['high'][symbol], 'low': input_data['low'][symbol]}}
            symbol_inputs = {{ {symbol_inputs_for_eager_call} }}

            # Execute the calculation immediately for this single symbol
            result_series_or_struct = plta.{func_name}(**symbol_inputs, **kwargs)

            # If this is a component of a multi-output function, extract the field.
            if "{output_component_name}":
                final_series = result_series_or_struct.struct.field("{output_component_name}")
            else:
                final_series = result_series_or_struct

            output_series_list.append(final_series.alias(symbol))

        # Combine the datetime column with the list of calculated series
        datetime_col_df = df_base.select(pl.col(DEFAULT_DATETIME_COL))
        result_df = datetime_col_df.with_columns(output_series_list)
        return result_df

"""

# --- Configuration ---
# Maps TA-Lib function names to their indicator group for directory organization.
# This dictionary is generated based on the user's provided list.
INDICATOR_GROUPS = {
    # Overlap Studies
    "bbands": "overlap_studies",
    "dema": "overlap_studies",
    "ema": "overlap_studies",
    "ht_trendline": "overlap_studies",
    "kama": "overlap_studies",
    "ma": "overlap_studies",
    "mama": "overlap_studies",
    "mavp": "overlap_studies",
    "midpoint": "overlap_studies",
    "midprice": "overlap_studies",
    "sar": "overlap_studies",
    "sarext": "overlap_studies",
    "sma": "overlap_studies",
    "t3": "overlap_studies",
    "tema": "overlap_studies",
    "trima": "overlap_studies",
    "wma": "overlap_studies",
    # Momentum Indicators
    "adx": "momentum_indicators",
    "adxr": "momentum_indicators",
    "apo": "momentum_indicators",
    "aroon": "momentum_indicators",
    "aroonosc": "momentum_indicators",
    "bop": "momentum_indicators",
    "cci": "momentum_indicators",
    "cmo": "momentum_indicators",
    "dx": "momentum_indicators",
    "macd": "momentum_indicators",
    "macdext": "momentum_indicators",
    "macdfix": "momentum_indicators",
    "mfi": "momentum_indicators",
    "minus_di": "momentum_indicators",
    "minus_dm": "momentum_indicators",
    "mom": "momentum_indicators",
    "plus_di": "momentum_indicators",
    "plus_dm": "momentum_indicators",
    "ppo": "momentum_indicators",
    "roc": "momentum_indicators",
    "rocp": "momentum_indicators",
    "rocr": "momentum_indicators",
    "rocr100": "momentum_indicators",
    "rsi": "momentum_indicators",
    "stoch": "momentum_indicators",
    "stochf": "momentum_indicators",
    "stochrsi": "momentum_indicators",
    "trix": "momentum_indicators",
    "ultosc": "momentum_indicators",
    "willr": "momentum_indicators",
    # Volume Indicators
    "ad": "volume_indicators",
    "adosc": "volume_indicators",
    "obv": "volume_indicators",
    # Cycle Indicators
    "ht_dcperiod": "cycle_indicators",
    "ht_dcphase": "cycle_indicators",
    "ht_phasor": "cycle_indicators",
    "ht_sine": "cycle_indicators",
    "ht_trendmode": "cycle_indicators",
    # Price Transform
    "avgprice": "price_transform",
    "medprice": "price_transform",
    "typprice": "price_transform",
    "wclprice": "price_transform",
    # Volatility Indicators
    "atr": "volatility_indicators",
    "natr": "volatility_indicators",
    "trange": "volatility_indicators",
    # Pattern Recognition
    "cdl2crows": "pattern_recognition",
    "cdl3blackcrows": "pattern_recognition",
    "cdl3inside": "pattern_recognition",
    "cdl3linestrike": "pattern_recognition",
    "cdl3outside": "pattern_recognition",
    "cdl3starsinsouth": "pattern_recognition",
    "cdl3whitesoldiers": "pattern_recognition",
    "cdlabandonedbaby": "pattern_recognition",
    "cdladvanceblock": "pattern_recognition",
    "cdlbelthold": "pattern_recognition",
    "cdlbreakaway": "pattern_recognition",
    "cdlclosingmarubozu": "pattern_recognition",
    "cdlconcealbabyswall": "pattern_recognition",
    "cdlcounterattack": "pattern_recognition",
    "cdldarkcloudcover": "pattern_recognition",
    "cdldoji": "pattern_recognition",
    "cdldojistar": "pattern_recognition",
    "cdldragonflydoji": "pattern_recognition",
    "cdlengulfing": "pattern_recognition",
    "cdleveningdojistar": "pattern_recognition",
    "cdleveningstar": "pattern_recognition",
    "cdlgapsidesidewhite": "pattern_recognition",
    "cdlgravestonedoji": "pattern_recognition",
    "cdlhammer": "pattern_recognition",
    "cdlhangingman": "pattern_recognition",
    "cdlharami": "pattern_recognition",
    "cdlharamicross": "pattern_recognition",
    "cdlhighwave": "pattern_recognition",
    "cdlhikkake": "pattern_recognition",
    "cdlhikkakemod": "pattern_recognition",
    "cdlhomingpigeon": "pattern_recognition",
    "cdlidentical3crows": "pattern_recognition",
    "cdlinneck": "pattern_recognition",
    "cdlinvertedhammer": "pattern_recognition",
    "cdlkicking": "pattern_recognition",
    "cdlkickingbylength": "pattern_recognition",
    "cdlladderbottom": "pattern_recognition",
    "cdllongleggeddoji": "pattern_recognition",
    "cdllongline": "pattern_recognition",
    "cdlmarubozu": "pattern_recognition",
    "cdlmatchinglow": "pattern_recognition",
    "cdlmathold": "pattern_recognition",
    "cdlmorningdojistar": "pattern_recognition",
    "cdlmorningstar": "pattern_recognition",
    "cdlonneck": "pattern_recognition",
    "cdlpiercing": "pattern_recognition",
    "cdlrickshawman": "pattern_recognition",
    "cdlrisefall3methods": "pattern_recognition",
    "cdlseparatinglines": "pattern_recognition",
    "cdlshootingstar": "pattern_recognition",
    "cdlshortline": "pattern_recognition",
    "cdlspinningtop": "pattern_recognition",
    "cdlstalledpattern": "pattern_recognition",
    "cdlsticksandwich": "pattern_recognition",
    "cdltakuri": "pattern_recognition",
    "cdltasukigap": "pattern_recognition",
    "cdlthrusting": "pattern_recognition",
    "cdltristar": "pattern_recognition",
    "cdlunique3river": "pattern_recognition",
    "cdlupsidegap2crows": "pattern_recognition",
    "cdlxsidegap3methods": "pattern_recognition",
    # Statistic Functions
    "beta": "statistic_functions",
    "correl": "statistic_functions",
    "linearreg": "statistic_functions",
    "linearreg_angle": "statistic_functions",
    "linearreg_intercept": "statistic_functions",
    "linearreg_slope": "statistic_functions",
    "stddev": "statistic_functions",
    "tsf": "statistic_functions",
    "var": "statistic_functions",
}

MULTI_OUTPUT_FUNCTIONS = {
    "bbands": ["upperband", "middleband", "lowerband"],
    "mama": ["mama", "fama"],
    "macd": ["macd", "macdsignal", "macdhist"],
    "macdext": ["macd", "macdsignal", "macdhist"],
    "macdfix": ["macd", "macdsignal", "macdhist"],
    "stoch": ["slowk", "slowd"],
    "stochf": ["fastk", "fastd"],
    "aroon": ["aroondown", "aroonup"],
    "ht_phasor": ["inphase", "quadrature"],
    "ht_sine": ["sine", "leadsine"],
}

INPUT_COLUMN_MAP = {
    "real": "close",
    "open": "open",
    "high": "high",
    "low": "low",
    "close": "close",
    "volume": "volume",
}


def generate_factor_files():
    """Main function to generate all factor files, organized by group."""
    print("--- Starting Factor File Generator ---")
    OUTPUT_DIR.mkdir(exist_ok=True)
    generated_files_by_group = defaultdict(list)

    for func_name, func_obj in inspect.getmembers(plta, inspect.isfunction):
        if func_name.startswith("_"):
            continue

        normalized_func_name = func_name.lower()
        group_name = INDICATOR_GROUPS.get(normalized_func_name, "uncategorized")
        group_dir = OUTPUT_DIR / group_name
        group_dir.mkdir(exist_ok=True)
        class_list_for_group = generated_files_by_group[group_name]

        if func_name in MULTI_OUTPUT_FUNCTIONS:
            for component in MULTI_OUTPUT_FUNCTIONS[func_name]:
                generate_single_factor_file(
                    group_dir,
                    func_name,
                    func_obj,
                    class_list_for_group,
                    output_component_name=component,
                )
        else:
            generate_single_factor_file(
                group_dir, func_name, func_obj, class_list_for_group
            )

    create_init_files(generated_files_by_group)
    print(f"\n--- Generation Complete: All files saved in '{OUTPUT_DIR.name}' ---")


def generate_single_factor_file(
    output_path, func_name, func_obj, class_list, output_component_name=None
):
    """Generates the code for a single factor class and writes it to a file."""
    print(
        f"  -> Processing: {func_name}"
        + (f" -> {output_component_name}" if output_component_name else "")
    )

    sig = inspect.signature(func_obj)
    params = sig.parameters

    required_input_cols = {INPUT_COLUMN_MAP[p] for p in params if p in INPUT_COLUMN_MAP}
    config_params = [
        p
        for p, v in params.items()
        if p not in INPUT_COLUMN_MAP and v.default is not inspect.Parameter.empty
    ]

    base_name = (
        f"{func_name.upper()}_{output_component_name.upper()}"
        if output_component_name
        else func_name.upper()
    )
    class_name = f"{base_name}"
    module_filename = f"{base_name.lower()}"

    param_validation_lines = []
    for p in config_params:
        param_validation_lines.extend(
            [
                f'        if not hasattr(self.params, "{p}"): raise ValueError(f"{{self.factor_key}} requires a \'{p}\' parameter.")',
                f"        try: self.{p} = float(self.params.{p})",
                f"        except (ValueError, TypeError): self.{p} = int(self.params.{p})",
            ]
        )

    # *** FIX IS HERE ***
    # This correctly generates the string for the 'symbol_inputs' dictionary
    # that will be used inside the loop for eager execution.
    eager_call_args = []
    for p_name in params:
        if p_name in INPUT_COLUMN_MAP:
            col_type = INPUT_COLUMN_MAP[p_name]
            eager_call_args.append(f'"{p_name}": input_data["{col_type}"][symbol]')
    symbol_inputs_for_eager_call_str = ", ".join(eager_call_args)

    code = FACTOR_CLASS_TEMPLATE.format(
        class_name=class_name,
        docstring=f"Calculates the {base_name} indicator.",
        factor_name=base_name,
        required_param_list=", ".join(config_params) or "None",
        param_validation_and_assignment="\n".join(param_validation_lines),
        input_data_validation="\n".join(
            [
                f'        if input_data.get("{c}") is None: return pl.DataFrame(data={{}}, schema=self.get_output_schema())'
                for c in required_input_cols
            ]
        ),
        func_name=func_name,
        kwargs_for_call=", ".join([f'"{p}": self.{p}' for p in config_params]),
        symbol_inputs_for_eager_call=symbol_inputs_for_eager_call_str,  # Pass the corrected string
        output_component_name=output_component_name or "",
    )

    file_path = output_path / f"{module_filename}.py"
    file_path.write_text(code, encoding="utf-8")
    class_list.append((module_filename, class_name))


def create_init_files(generated_files_by_group):
    """Creates all necessary __init__.py files to form a package."""
    for group_name, classes in generated_files_by_group.items():
        init_path = OUTPUT_DIR / group_name / "__init__.py"
        with init_path.open("w", encoding="utf-8") as f:
            for module_name, class_name in sorted(classes):
                f.write(f"from .{module_name} import {class_name}\n")

    top_init_path = OUTPUT_DIR / "__init__.py"
    with top_init_path.open("w", encoding="utf-8") as f:
        all_class_names = []
        for group_name, classes in sorted(generated_files_by_group.items()):
            class_names = sorted([c[1] for c in classes])
            all_class_names.extend(class_names)
            f.write(
                f"from .{group_name} import (\n    "
                + ",\n    ".join(class_names)
                + "\n)\n\n"
            )
        f.write(
            "\n__all__ = [\n    " + '",\n    "'.join(sorted(all_class_names)) + '"\n]\n'
        )


if __name__ == "__main__":
    generate_factor_files()
