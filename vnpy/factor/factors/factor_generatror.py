import inspect
from collections import defaultdict
from pathlib import Path

# The library to inspect and generate wrappers for
import polars_talib as plta

# The directory where the new factor files will be saved
OUTPUT_DIR = Path(__file__).parent / "ta_lib"

# A template for the Python code of each new factor class.
# This version is updated with all necessary methods and correct logic.
FACTOR_CLASS_TEMPLATE = """# Auto-generated by factor_generator.py using polars-talib
import polars as pl
import polars_talib as plta
from typing import Dict, List

from vnpy.factor.template import FactorTemplate
from vnpy.factor.memory import FactorMemory

DEFAULT_DATETIME_COL = "datetime"


class {class_name}(FactorTemplate):
    \"\"\"
    {docstring}
    \"\"\"

    author = "Auto-Generated by FactorGenerator"
    factor_name = "{factor_name}"

    def __init__(self, setting: dict | None = None, **kwargs):
        \"\"\"
        Initializes the {class_name}.
        Required parameters: {required_param_list}
        \"\"\"
        super().__init__(setting, **kwargs)

        # --- Parameter Validation and Assignment ---
{param_validation_and_assignment}

    def calculate(self, input_data: dict[str, pl.DataFrame], memory: FactorMemory) -> pl.DataFrame:
        \"\"\"Calculates the indicator using a temporary DataFrame and expression API for each symbol.\"\"\"
        # --- Input Data Validation ---
{input_data_validation}

        # --- Eager Calculation Loop ---
        df_base = input_data.get("close")
        symbol_columns = [col for col in df_base.columns if col != DEFAULT_DATETIME_COL]
        if self.vt_symbols:
            symbol_columns = [col for col in symbol_columns if col in self.vt_symbols]

        if not symbol_columns:
            return pl.DataFrame(data={{}}, schema=self.get_output_schema())

        kwargs = {{ {kwargs_for_call} }}
        output_series_list = []

        for symbol in symbol_columns:
            # 1. Create a temporary DataFrame with this symbol's required inputs
            temp_df_inputs = {{ {symbol_inputs_for_temp_df} }}
            input_df = pl.DataFrame(temp_df_inputs)

            # 2. Define the calculation expression using pl.col()
            calc_expression = plta.{func_name}({expression_inputs}, **kwargs).alias("result")

            # 3. Execute the expression on the temporary DataFrame
            result_df_with_indicator = input_df.with_columns(calc_expression)

            result_series_or_struct = result_df_with_indicator.get_column("result")

            # 4. Handle multi-output indicators if necessary using index access
            if {is_multi_output}:
                final_series = result_series_or_struct.struct[{output_component_index}]
            else:
                final_series = result_series_or_struct

            output_series_list.append(final_series.alias(symbol))

        # Combine the datetime column with the list of calculated series
        datetime_col_df = df_base.select(pl.col(DEFAULT_DATETIME_COL))
        result_df = datetime_col_df.with_columns(output_series_list)
        return result_df

"""

# --- Configuration Dictionaries ---
INDICATOR_GROUPS = {
    # Overlap Studies
    "bbands": "overlap_studies",
    "dema": "overlap_studies",
    "ema": "overlap_studies",
    "ht_trendline": "overlap_studies",
    "kama": "overlap_studies",
    "ma": "overlap_studies",
    "mama": "overlap_studies",
    "mavp": "overlap_studies",
    "midpoint": "overlap_studies",
    "midprice": "overlap_studies",
    "sar": "overlap_studies",
    "sarext": "overlap_studies",
    "sma": "overlap_studies",
    "t3": "overlap_studies",
    "tema": "overlap_studies",
    "trima": "overlap_studies",
    "wma": "overlap_studies",
    # Momentum Indicators
    "adx": "momentum_indicators",
    "adxr": "momentum_indicators",
    "apo": "momentum_indicators",
    "aroon": "momentum_indicators",
    "aroonosc": "momentum_indicators",
    "bop": "momentum_indicators",
    "cci": "momentum_indicators",
    "cmo": "momentum_indicators",
    "dx": "momentum_indicators",
    "macd": "momentum_indicators",
    "macdext": "momentum_indicators",
    "macdfix": "momentum_indicators",
    "mfi": "momentum_indicators",
    "minus_di": "momentum_indicators",
    "minus_dm": "momentum_indicators",
    "mom": "momentum_indicators",
    "plus_di": "momentum_indicators",
    "plus_dm": "momentum_indicators",
    "ppo": "momentum_indicators",
    "roc": "momentum_indicators",
    "rocp": "momentum_indicators",
    "rocr": "momentum_indicators",
    "rocr100": "momentum_indicators",
    "rsi": "momentum_indicators",
    "stoch": "momentum_indicators",
    "stochf": "momentum_indicators",
    "stochrsi": "momentum_indicators",
    "trix": "momentum_indicators",
    "ultosc": "momentum_indicators",
    "willr": "momentum_indicators",
    # Volume Indicators
    "ad": "volume_indicators",
    "adosc": "volume_indicators",
    "obv": "volume_indicators",
    # Cycle Indicators
    "ht_dcperiod": "cycle_indicators",
    "ht_dcphase": "cycle_indicators",
    "ht_phasor": "cycle_indicators",
    "ht_sine": "cycle_indicators",
    "ht_trendmode": "cycle_indicators",
    # Price Transform
    "avgprice": "price_transform",
    "medprice": "price_transform",
    "typprice": "price_transform",
    "wclprice": "price_transform",
    # Volatility Indicators
    "atr": "volatility_indicators",
    "natr": "volatility_indicators",
    "trange": "volatility_indicators",
    # Pattern Recognition
    "cdl2crows": "pattern_recognition",
    "cdl3blackcrows": "pattern_recognition",
    "cdl3inside": "pattern_recognition",
    "cdl3linestrike": "pattern_recognition",
    "cdl3outside": "pattern_recognition",
    "cdl3starsinsouth": "pattern_recognition",
    "cdl3whitesoldiers": "pattern_recognition",
    "cdlabandonedbaby": "pattern_recognition",
    "cdladvanceblock": "pattern_recognition",
    "cdlbelthold": "pattern_recognition",
    "cdlbreakaway": "pattern_recognition",
    "cdlclosingmarubozu": "pattern_recognition",
    "cdlconcealbabyswall": "pattern_recognition",
    "cdlcounterattack": "pattern_recognition",
    "cdldarkcloudcover": "pattern_recognition",
    "cdldoji": "pattern_recognition",
    "cdldojistar": "pattern_recognition",
    "cdldragonflydoji": "pattern_recognition",
    "cdlengulfing": "pattern_recognition",
    "cdleveningdojistar": "pattern_recognition",
    "cdleveningstar": "pattern_recognition",
    "cdlgapsidesidewhite": "pattern_recognition",
    "cdlgravestonedoji": "pattern_recognition",
    "cdlhammer": "pattern_recognition",
    "cdlhangingman": "pattern_recognition",
    "cdlharami": "pattern_recognition",
    "cdlharamicross": "pattern_recognition",
    "cdlhighwave": "pattern_recognition",
    "cdlhikkake": "pattern_recognition",
    "cdlhikkakemod": "pattern_recognition",
    "cdlhomingpigeon": "pattern_recognition",
    "cdlidentical3crows": "pattern_recognition",
    "cdlinneck": "pattern_recognition",
    "cdlinvertedhammer": "pattern_recognition",
    "cdlkicking": "pattern_recognition",
    "cdlkickingbylength": "pattern_recognition",
    "cdlladderbottom": "pattern_recognition",
    "cdllongleggeddoji": "pattern_recognition",
    "cdllongline": "pattern_recognition",
    "cdlmarubozu": "pattern_recognition",
    "cdlmatchinglow": "pattern_recognition",
    "cdlmathold": "pattern_recognition",
    "cdlmorningdojistar": "pattern_recognition",
    "cdlmorningstar": "pattern_recognition",
    "cdlonneck": "pattern_recognition",
    "cdlpiercing": "pattern_recognition",
    "cdlrickshawman": "pattern_recognition",
    "cdlrisefall3methods": "pattern_recognition",
    "cdlseparatinglines": "pattern_recognition",
    "cdlshootingstar": "pattern_recognition",
    "cdlshortline": "pattern_recognition",
    "cdlspinningtop": "pattern_recognition",
    "cdlstalledpattern": "pattern_recognition",
    "cdlsticksandwich": "pattern_recognition",
    "cdltakuri": "pattern_recognition",
    "cdltasukigap": "pattern_recognition",
    "cdlthrusting": "pattern_recognition",
    "cdltristar": "pattern_recognition",
    "cdlunique3river": "pattern_recognition",
    "cdlupsidegap2crows": "pattern_recognition",
    "cdlxsidegap3methods": "pattern_recognition",
}
MULTI_OUTPUT_FUNCTIONS = {
    "bbands": ["upperband", "middleband", "lowerband"],
    "macd": ["macd", "macdsignal", "macdhist"],
    "stoch": ["slowk", "slowd"],
    "stochf": ["fastk", "fastd"],
    "aroon": ["aroondown", "aroonup"],
}

INPUT_COLUMN_MAP = {
    "real": "close",
    "price": "close",
    "open": "open",
    "high": "high",
    "low": "low",
    "close": "close",
    "volume": "volume",
}

INDICATOR_GROUPS_EXCLUDED = {
    "macdext",
    "midpoint",
    "sarext",
    "macdfix",
    "rocp",
    "ht_dcphase",
    "ht_trendline",
    "dx",
    "rocr100",
    "minus_dm",
    "midprice",
    "kama",
    "medprice",
    "avgprice",
    "ht_dcperiod",
    "ema",
    "wclprice",
    "sma",
    "minus_di",
    "ht_phasor",
    "ma",
    "trange",
    "t3",
    "plus_di",
    "mavp",
    "ht_sine",
    "ht_trendmode",
    "plus_dm",
    "mama",
    "dema",
    "rocr",
    "tema",
    "trima",
    "wma",
    "typprice",
}


def generate_single_factor_file(
    output_path,
    func_name,
    func_obj,
    class_list,
    output_component_name=None,
    output_component_index=None,
):
    """Generates the code for a single factor class and writes it to a file."""
    print(
        f"  -> Processing: {func_name}"
        + (f" -> {output_component_name}" if output_component_name else "")
    )

    sig = inspect.signature(func_obj)
    params = sig.parameters

    required_input_cols = {INPUT_COLUMN_MAP[p] for p in params if p in INPUT_COLUMN_MAP}
    config_params = [
        p
        for p, v in params.items()
        if p not in INPUT_COLUMN_MAP and v.default is not inspect.Parameter.empty
    ]

    base_name = (
        f"{func_name.upper()}_{output_component_name.upper()}"
        if output_component_name
        else func_name.upper()
    )
    class_name = f"{base_name}"
    module_filename = f"{base_name.lower()}"

    # Corrected parameter validation logic
    param_validation_lines = [
        f'        if not hasattr(self.params, "{p}"): raise ValueError(f"{{self.factor_key}} requires a \'{p}\' parameter.")\n'
        f"        try: self.{p} = int(self.params.{p})\n"
        f"        except (ValueError, TypeError): self.{p} = float(self.params.{p})"
        for p in config_params
    ]

    # Logic to build arguments for the temporary DataFrame and the expression
    temp_df_args = [
        f'"{p_name}": input_data["{INPUT_COLUMN_MAP[p_name]}"][symbol]'
        for p_name in params
        if p_name in INPUT_COLUMN_MAP
    ]
    expression_inputs_args = [
        f'{p_name}=pl.col("{p_name}")'
        for p_name in params
        if p_name in INPUT_COLUMN_MAP
    ]

    # Robust input validation string
    input_validation_str = "\n".join(
        [
            f'        if input_data["{c}"].is_empty(): return pl.DataFrame(data={{}}, schema=self.get_output_schema())'
            for c in required_input_cols
        ]
    )

    code = FACTOR_CLASS_TEMPLATE.format(
        class_name=class_name,
        docstring=f"Calculates the {base_name} indicator.",
        factor_name=base_name,
        required_param_list=", ".join(config_params) or "None",
        param_validation_and_assignment="\n".join(param_validation_lines),
        input_data_validation=input_validation_str,
        func_name=func_name,
        kwargs_for_call=", ".join([f'"{p}": self.{p}' for p in config_params]),
        symbol_inputs_for_temp_df=", ".join(temp_df_args),
        expression_inputs=", ".join(expression_inputs_args),
        is_multi_output=True if output_component_name else False,
        output_component_index=output_component_index,
    )

    file_path = output_path / f"{module_filename}.py"
    file_path.write_text(code, encoding="utf-8")
    class_list.append((module_filename, class_name))


def create_init_files(generated_files_by_group):
    """Creates all necessary __init__.py files to form a package."""
    for group_name, classes in generated_files_by_group.items():
        init_path = OUTPUT_DIR / group_name / "__init__.py"
        with init_path.open("w", encoding="utf-8") as f:
            for module_name, class_name in sorted(classes):
                f.write(f"from .{module_name} import {class_name}\n")

    top_init_path = OUTPUT_DIR / "__init__.py"
    with top_init_path.open("w", encoding="utf-8") as f:
        all_class_names = [
            c[1] for classes in generated_files_by_group.values() for c in classes
        ]
        f.write("# Auto-generated by factor_generator.py\n\n")
        for group_name, classes in sorted(generated_files_by_group.items()):
            class_names = sorted([c[1] for c in classes])
            f.write(
                f"from .{group_name} import (\n    "
                + ",\n    ".join(class_names)
                + "\n)\n\n"
            )
        f.write(
            "\n__all__ = [\n    '"
            + "',\n    '".join(sorted(all_class_names))
            + "'\n]\n"
        )


def generate_factor_files():
    """Main function to generate all factor files, organized by group."""
    print("--- Starting Factor File Generator ---")
    OUTPUT_DIR.mkdir(exist_ok=True)
    generated_files_by_group = defaultdict(list)

    for func_name, func_obj in inspect.getmembers(plta, inspect.isfunction):
        if func_name.startswith("_"):
            continue

        normalized_func_name = func_name.lower()
        if normalized_func_name not in INDICATOR_GROUPS:
            continue

        if normalized_func_name in INDICATOR_GROUPS_EXCLUDED:
            continue

        group_name = INDICATOR_GROUPS.get(normalized_func_name, "uncategorized")
        group_dir = OUTPUT_DIR / group_name
        group_dir.mkdir(exist_ok=True)
        class_list_for_group = generated_files_by_group[group_name]

        if func_name in MULTI_OUTPUT_FUNCTIONS:
            for index, component in enumerate(MULTI_OUTPUT_FUNCTIONS[func_name]):
                generate_single_factor_file(
                    group_dir,
                    func_name,
                    func_obj,
                    class_list_for_group,
                    output_component_name=component,
                    output_component_index=index,
                )
        else:
            generate_single_factor_file(
                group_dir, func_name, func_obj, class_list_for_group
            )

    create_init_files(generated_files_by_group)
    print(f"\n--- Generation Complete: All files saved in '{OUTPUT_DIR.name}' ---")


if __name__ == "__main__":
    generate_factor_files()
