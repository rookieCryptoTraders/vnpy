import inspect
from collections import defaultdict
from pathlib import Path

# The library to inspect and generate wrappers for
import polars_talib as plta

# The directory where the new factor files will be saved
OUTPUT_DIR = Path(
    "/Users/chenzhao/Documents/crypto_vnpy/vnpy/vnpy/factor/factors/ta-lib"
)

# A template for the Python code of each new factor class.
# Placeholders like {class_name}, {factor_name}, etc., will be filled in.
FACTOR_CLASS_TEMPLATE = """# Auto-generated by factor_generator using polats ta-lib.py
import polars as pl
import polars_talib as plta

from vnpy.factor.template import FactorTemplate
from vnpy.factor.memory import FactorMemory

DEFAULT_DATETIME_COL = "datetime"


class {class_name}(FactorTemplate):
    \"\"\"
    {docstring}
    \"\"\"

    author = "Auto-Generated by FactorGenerator"
    factor_name = "{factor_name}"

    def __init__(self, setting: dict | None = None, vt_symbols: list[str] | None = None, **kwargs):
        \"\"\"
        Initializes the {class_name}.
        Required parameters: {required_param_list}
        \"\"\"
        super().__init__(setting, **kwargs)
        self.vt_symbols: list[str] = vt_symbols if vt_symbols else []

        # --- Parameter Validation and Assignment ---
{param_validation_and_assignment}


    def calculate(self, input_data: dict[str, pl.DataFrame], memory: FactorMemory) -> pl.DataFrame:
        \"\"\"Calculates the indicator and extracts the relevant component if necessary.\"\"\"
        # --- Input Data Validation ---
{input_data_validation}

        # --- Core Calculation ---
        df_base = input_data.get("close") or next(iter(input_data.values()))

        symbol_columns = [col for col in df_base.columns if col != DEFAULT_DATETIME_COL]
        if self.vt_symbols:
            symbol_columns = [col for col in symbol_columns if col in self.vt_symbols]

        if not symbol_columns:
            return pl.DataFrame(data={{}}, schema=self.get_output_schema())

        kwargs = {{ {kwargs_for_call} }}
        expressions_to_run = []

        for symbol in symbol_columns:
            symbol_inputs = {{ {symbol_inputs_for_call} }}

            result_expr = plta.{func_name}(**symbol_inputs, **kwargs)

            # If this is a component of a multi-output function, extract the field.
            if "{output_component_name}":
                result_expr = result_expr.struct.field("{output_component_name}")

            expressions_to_run.append(result_expr.alias(symbol))

        # Join all necessary input dataframes for the calculation
        df_exec_base = df_base
        for col_name, df_wide in input_data.items():
            if col_name != "close" and col_name in {required_input_cols_repr}:
                if df_wide is not df_base:
                    df_exec_base = df_exec_base.join(df_wide.select(pl.all().exclude(DEFAULT_DATETIME_COL)), on=DEFAULT_DATETIME_COL, how="left")

        # Execute all expressions at once
        result_df = df_exec_base.select(pl.col(DEFAULT_DATETIME_COL), *expressions_to_run)
        return result_df

"""

# --- Configuration ---
# Maps TA-Lib function names to their indicator group for directory organization.
# This dictionary is generated based on the user's provided list.
INDICATOR_GROUPS = {
    # Overlap Studies
    "bbands": "overlap_studies",
    "dema": "overlap_studies",
    "ema": "overlap_studies",
    "ht_trendline": "overlap_studies",
    "kama": "overlap_studies",
    "ma": "overlap_studies",
    "mama": "overlap_studies",
    "mavp": "overlap_studies",
    "midpoint": "overlap_studies",
    "midprice": "overlap_studies",
    "sar": "overlap_studies",
    "sarext": "overlap_studies",
    "sma": "overlap_studies",
    "t3": "overlap_studies",
    "tema": "overlap_studies",
    "trima": "overlap_studies",
    "wma": "overlap_studies",
    # Momentum Indicators
    "adx": "momentum_indicators",
    "adxr": "momentum_indicators",
    "apo": "momentum_indicators",
    "aroon": "momentum_indicators",
    "aroonosc": "momentum_indicators",
    "bop": "momentum_indicators",
    "cci": "momentum_indicators",
    "cmo": "momentum_indicators",
    "dx": "momentum_indicators",
    "macd": "momentum_indicators",
    "macdext": "momentum_indicators",
    "macdfix": "momentum_indicators",
    "mfi": "momentum_indicators",
    "minus_di": "momentum_indicators",
    "minus_dm": "momentum_indicators",
    "mom": "momentum_indicators",
    "plus_di": "momentum_indicators",
    "plus_dm": "momentum_indicators",
    "ppo": "momentum_indicators",
    "roc": "momentum_indicators",
    "rocp": "momentum_indicators",
    "rocr": "momentum_indicators",
    "rocr100": "momentum_indicators",
    "rsi": "momentum_indicators",
    "stoch": "momentum_indicators",
    "stochf": "momentum_indicators",
    "stochrsi": "momentum_indicators",
    "trix": "momentum_indicators",
    "ultosc": "momentum_indicators",
    "willr": "momentum_indicators",
    # Volume Indicators
    "ad": "volume_indicators",
    "adosc": "volume_indicators",
    "obv": "volume_indicators",
    # Cycle Indicators
    "ht_dcperiod": "cycle_indicators",
    "ht_dcphase": "cycle_indicators",
    "ht_phasor": "cycle_indicators",
    "ht_sine": "cycle_indicators",
    "ht_trendmode": "cycle_indicators",
    # Price Transform
    "avgprice": "price_transform",
    "medprice": "price_transform",
    "typprice": "price_transform",
    "wclprice": "price_transform",
    # Volatility Indicators
    "atr": "volatility_indicators",
    "natr": "volatility_indicators",
    "trange": "volatility_indicators",
    # Pattern Recognition
    "cdl2crows": "pattern_recognition",
    "cdl3blackcrows": "pattern_recognition",
    "cdl3inside": "pattern_recognition",
    "cdl3linestrike": "pattern_recognition",
    "cdl3outside": "pattern_recognition",
    "cdl3starsinsouth": "pattern_recognition",
    "cdl3whitesoldiers": "pattern_recognition",
    "cdlabandonedbaby": "pattern_recognition",
    "cdladvanceblock": "pattern_recognition",
    "cdlbelthold": "pattern_recognition",
    "cdlbreakaway": "pattern_recognition",
    "cdlclosingmarubozu": "pattern_recognition",
    "cdlconcealbabyswall": "pattern_recognition",
    "cdlcounterattack": "pattern_recognition",
    "cdldarkcloudcover": "pattern_recognition",
    "cdldoji": "pattern_recognition",
    "cdldojistar": "pattern_recognition",
    "cdldragonflydoji": "pattern_recognition",
    "cdlengulfing": "pattern_recognition",
    "cdleveningdojistar": "pattern_recognition",
    "cdleveningstar": "pattern_recognition",
    "cdlgapsidesidewhite": "pattern_recognition",
    "cdlgravestonedoji": "pattern_recognition",
    "cdlhammer": "pattern_recognition",
    "cdlhangingman": "pattern_recognition",
    "cdlharami": "pattern_recognition",
    "cdlharamicross": "pattern_recognition",
    "cdlhighwave": "pattern_recognition",
    "cdlhikkake": "pattern_recognition",
    "cdlhikkakemod": "pattern_recognition",
    "cdlhomingpigeon": "pattern_recognition",
    "cdlidentical3crows": "pattern_recognition",
    "cdlinneck": "pattern_recognition",
    "cdlinvertedhammer": "pattern_recognition",
    "cdlkicking": "pattern_recognition",
    "cdlkickingbylength": "pattern_recognition",
    "cdlladderbottom": "pattern_recognition",
    "cdllongleggeddoji": "pattern_recognition",
    "cdllongline": "pattern_recognition",
    "cdlmarubozu": "pattern_recognition",
    "cdlmatchinglow": "pattern_recognition",
    "cdlmathold": "pattern_recognition",
    "cdlmorningdojistar": "pattern_recognition",
    "cdlmorningstar": "pattern_recognition",
    "cdlonneck": "pattern_recognition",
    "cdlpiercing": "pattern_recognition",
    "cdlrickshawman": "pattern_recognition",
    "cdlrisefall3methods": "pattern_recognition",
    "cdlseparatinglines": "pattern_recognition",
    "cdlshootingstar": "pattern_recognition",
    "cdlshortline": "pattern_recognition",
    "cdlspinningtop": "pattern_recognition",
    "cdlstalledpattern": "pattern_recognition",
    "cdlsticksandwich": "pattern_recognition",
    "cdltakuri": "pattern_recognition",
    "cdltasukigap": "pattern_recognition",
    "cdlthrusting": "pattern_recognition",
    "cdltristar": "pattern_recognition",
    "cdlunique3river": "pattern_recognition",
    "cdlupsidegap2crows": "pattern_recognition",
    "cdlxsidegap3methods": "pattern_recognition",
    # Statistic Functions
    "beta": "statistic_functions",
    "correl": "statistic_functions",
    "linearreg": "statistic_functions",
    "linearreg_angle": "statistic_functions",
    "linearreg_intercept": "statistic_functions",
    "linearreg_slope": "statistic_functions",
    "stddev": "statistic_functions",
    "tsf": "statistic_functions",
    "var": "statistic_functions",
}

MULTI_OUTPUT_FUNCTIONS = {
    "bbands": ["upperband", "middleband", "lowerband"],
    "mama": ["mama", "fama"],
    "macd": ["macd", "macdsignal", "macdhist"],
    "macdext": ["macd", "macdsignal", "macdhist"],
    "macdfix": ["macd", "macdsignal", "macdhist"],
    "stoch": ["slowk", "slowd"],
    "stochf": ["fastk", "fastd"],
    "aroon": ["aroondown", "aroonup"],
    "ht_phasor": ["inphase", "quadrature"],
    "ht_sine": ["sine", "leadsine"],
}

INPUT_COLUMN_MAP = {
    "real": "close",
    "open": "open",
    "high": "high",
    "low": "low",
    "close": "close",
    "volume": "volume",
}


def generate_factor_files():
    """
    Inspects polars_talib, generates a .py file for each factor class, and
    organizes them into subdirectories based on their indicator group.
    """
    print("--- Starting Factor File Generator ---")
    OUTPUT_DIR.mkdir(exist_ok=True)

    # Use a dictionary to store lists of generated classes for each group
    generated_files_by_group = defaultdict(list)

    for func_name, func_obj in inspect.getmembers(plta, inspect.isfunction):
        if func_name.startswith("_"):
            continue

        # Determine the output directory for this function's group
        # Normalize the function name from inspect to match keys in our dict
        normalized_func_name = func_name.lower()
        group_name = INDICATOR_GROUPS.get(normalized_func_name, "uncategorized")

        group_dir = OUTPUT_DIR / group_name
        group_dir.mkdir(exist_ok=True)

        # Get the list where we will store the generated class info for this group
        class_list_for_group = generated_files_by_group[group_name]

        if func_name in MULTI_OUTPUT_FUNCTIONS:
            for component in MULTI_OUTPUT_FUNCTIONS[func_name]:
                generate_single_factor_file(
                    group_dir,
                    func_name,
                    func_obj,
                    class_list_for_group,
                    output_component_name=component,
                )
        else:
            generate_single_factor_file(
                group_dir, func_name, func_obj, class_list_for_group
            )

    # --- Create __init__.py files to make directories into packages ---
    # First, create an __init__.py for each subdirectory
    for group_name, generated_classes in generated_files_by_group.items():
        group_dir = OUTPUT_DIR / group_name
        init_path = group_dir / "__init__.py"
        with open(init_path, "w", encoding="utf-8") as f:
            f.write(f"# Auto-generated __init__.py for {group_name}\n\n")
            for module_name, class_name in sorted(generated_classes):
                f.write(f"from .{module_name} import {class_name}\n")

    # Second, create a top-level __init__.py that imports from all subdirectories
    top_level_init_path = OUTPUT_DIR / "__init__.py"
    with open(top_level_init_path, "w", encoding="utf-8") as f:
        f.write("# Auto-generated by factor_generator.py\n\n")
        all_classes_list = []
        for group_name, group_classes in sorted(generated_files_by_group.items()):
            class_names = [cls[1] for cls in group_classes]
            all_classes_list.extend(class_names)
            # Create a nice import block for each group
            f.write(f"from .{group_name} import (\n")
            for class_name in sorted(class_names):
                f.write(f"    {class_name},\n")
            f.write(")\n\n")

        # Add an __all__ list for cleaner imports
        f.write("\n__all__ = [\n")
        for class_name in sorted(all_classes_list):
            f.write(f'    "{class_name}",\n')
        f.write("]\n")

    print("\n--- Generation Complete: All factor files organized by group. ---")
    print(
        f"All files saved in the '{OUTPUT_DIR.name}' directory and its subdirectories."
    )


def generate_single_factor_file(
    output_path: Path,
    func_name,
    func_obj,
    generated_classes_in_group,
    output_component_name=None,
):
    """Generates the code for a single factor class and writes it to a file in the specified path."""
    print(
        f"Processing function: {func_name}"
        + (f" -> {output_component_name}" if output_component_name else "")
    )

    sig = inspect.signature(func_obj)
    params = sig.parameters

    required_input_cols = {INPUT_COLUMN_MAP[p] for p in params if p in INPUT_COLUMN_MAP}
    config_params = [
        p
        for p, v in params.items()
        if p not in INPUT_COLUMN_MAP and v.default is not inspect.Parameter.empty
    ]

    base_name = (
        f"{func_name.upper()}_{output_component_name.upper()}"
        if output_component_name
        else func_name.upper()
    )
    class_name = f"{base_name}Factor"
    factor_name = base_name
    module_filename = f"{base_name.lower()}_factor"

    docstring = f"Calculates the {factor_name} indicator."
    required_param_list = ", ".join(config_params) or "None"

    param_validation_lines = []
    for p in config_params:
        param_validation_lines.append(
            f'        if not hasattr(self.params, "{p}"): raise ValueError(f"{{self.factor_key}} requires a \'{p}\' parameter.")'
        )
        param_validation_lines.append(f"        try: self.{p} = float(self.params.{p})")
        param_validation_lines.append(
            f"        except (ValueError, TypeError): self.{p} = int(self.params.{p})"
        )
    param_validation_and_assignment = "\n".join(param_validation_lines)

    input_validation_lines = [
        f'        if input_data.get("{col}") is None or input_data["{col}"].is_empty(): return pl.DataFrame(data={{}}, schema=self.get_output_schema())'
        for col in required_input_cols
    ]

    kwargs_for_call = ", ".join([f'"{p}": self.{p}' for p in config_params])
    symbol_inputs_for_call = ", ".join(
        [f'"{p}": pl.col(symbol)' for p in params if p in INPUT_COLUMN_MAP]
    )

    code = FACTOR_CLASS_TEMPLATE.format(
        class_name=class_name,
        docstring=docstring,
        factor_name=factor_name,
        required_param_list=required_param_list,
        param_validation_and_assignment=param_validation_and_assignment,
        input_data_validation="\n".join(input_validation_lines),
        required_input_cols_repr=repr(required_input_cols),
        func_name=func_name,
        kwargs_for_call=kwargs_for_call,
        symbol_inputs_for_call=symbol_inputs_for_call,
        output_component_name=output_component_name or "",
    )

    file_path = output_path / f"{module_filename}.py"  # Use the passed path
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(code)

    generated_classes_in_group.append((module_filename, class_name))


if __name__ == "__main__":
    generate_factor_files()
